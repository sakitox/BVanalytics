{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68ffd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from causalimpact import CausalImpact\n",
    "import csv\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import dtw\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32cf285",
   "metadata": {},
   "source": [
    "principal variables:\n",
    "test set\n",
    "up to 5 initial like-for-like csv datasets\n",
    "metric to aggregate by in a str\n",
    "rolling window\n",
    "min number of time periods in markets (find best recommended)\n",
    "min number of time periods in test set (find best recommended)\n",
    "\n",
    "optional:\n",
    "queries to be excuded in a list (possibly)\n",
    "countries\n",
    "outlier cutoff\n",
    "\n",
    "returns a csv ready to find matching markets\n",
    "\n",
    "actions on transform():\n",
    "check column names\n",
    "get test_set, test it is not empty\n",
    "groupby, sum/mean\n",
    "filter by test_set\n",
    "rename test markets to 'test'\n",
    "groupby, sum/mean\n",
    "    returns:\n",
    "    one or many DataFrames if 'queries' or 'countries' non empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8836c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp = pd.read_excel('C:/Users/akiro/Documents/Adidas/USA/us_test_06_pdp_titles_categories/data/inputs/pdps.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3e7bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('C:/Users/akiro/Documents/Adidas/USA/us_test_06_pdp_titles_categories/data/inputs/us_2021_11.csv')\n",
    "data2 = pd.read_csv('C:/Users/akiro/Documents/Adidas/USA/us_test_06_pdp_titles_categories/data/inputs/bq-all.csv')\n",
    "data1 = data1.groupby(['date','page']).sum().reset_index()\n",
    "data1 = data1[['date', 'page', 'impressions']]\n",
    "data2 = data2[['date', 'page', 'impressions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b481a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data1,data2], ignore_index=True).sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ec869ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(testset=pd.DataFrame(), dataset=pd.DataFrame(), metric='impressions', ranks='date',\n",
    "              col='page', roll=2, outlier=1, scaling=True, min_test=320, min_data=300, metric2='sum'):\n",
    "\n",
    "    testset.columns = testset.columns.str.lower()\n",
    "    dataset.columns = dataset.columns.str.lower()\n",
    "    col = col.lower()\n",
    "    \n",
    "    assert testset[col].name == testset[col].name, 'Column names must match for the matched markets'\n",
    "    \n",
    "    if metric2 == 'sum':\n",
    "        causal_input = dataset.groupby([ranks, col]).sum().sort_values(ranks, ascending=False).reset_index()\n",
    "    elif metric2 == 'mean':\n",
    "        causal_input = causal_input.groupby([ranks, col]).mean().sort_values(ranks, ascending=False).reset_index()\n",
    "    else:\n",
    "        raise ValueError('Supported aggregators are sum and mean')\n",
    "\n",
    "    test_set = causal_input[causal_input[col].isin(pdp[col])]\n",
    "    \n",
    "    assert (test_set.iloc[1,:].all() != None)  & (test_set.iloc[0,:].all() != None), 'No markets match on test and data, check strings'\n",
    "\n",
    "    testcount = test_set.groupby([col]).count().sort_values(metric, ascending=False).reset_index()\n",
    "    \n",
    "    assert testcount[metric].max() >= min_test, 'min_test must be lower than the maximum number of observations in testset'\n",
    "    \n",
    "    test_tops = testcount[testcount[ranks] >= min_test].reset_index()\n",
    "    \n",
    "    if metric2 == 'sum':\n",
    "        test_set =  causal_input[causal_input[col].isin(test_tops[col])]\n",
    "        test_set = test_set.groupby([ranks, col]).sum().sort_values(ranks, ascending=False).reset_index()\n",
    "    elif metric2 == 'mean':\n",
    "        test_set =  causal_input[causal_input[col].isin(test_tops[col])]\n",
    "        test_set = test_set.groupby([ranks, col]).mean().sort_values(ranks, ascending=False).reset_index()\n",
    "        \n",
    "    if outlier != 1:\n",
    "        test_set_clean = pd.DataFrame()\n",
    "        for i in test_tops[col].unique():\n",
    "            cutoff = test_set[test_set[col] == i].quantile(outlier)\n",
    "            temp = test_set[test_set[col] == i]\n",
    "            temp = temp[temp[metric] < cutoff[0]]\n",
    "            test_set_clean = pd.concat([test_set_clean, temp], ignore_index=True)\n",
    "            test_set = test_set_clean\n",
    "\n",
    "        causal_input = causal_input[~causal_input[col].isin(testcount[col])]\n",
    "        causal_input = pd.concat([causal_input, test_set], ignore_index=True).sort_values(ranks)\n",
    "    \n",
    "    causal_input.loc[causal_input[col].isin(test_tops[col]), col] = 'TEST'\n",
    "    \n",
    "    if metric2 == 'sum':\n",
    "        causal_input = causal_input.groupby([ranks, col]).sum().sort_values(ranks, ascending=True).reset_index()\n",
    "    elif metric2 == 'mean':\n",
    "        causal_input = causal_input.groupby([ranks, col]).mean().sort_values(ranks, ascending=True).reset_index()\n",
    "    else:\n",
    "        raise ValueError('Supported aggregators are sum and mean')\n",
    "    \n",
    "    marketcount = causal_input.groupby([col]).count().sort_values(metric, ascending=False).reset_index()\n",
    "\n",
    "    if marketcount[marketcount[col] == 'TEST'][metric].max() <= min_data:\n",
    "        min_data = marketcount[marketcount[col] == 'TEST'][metric].max()\n",
    "    \n",
    "    assert marketcount[metric].max() >= min_data, 'min_data must be lower than the maximum number of observations in dataset'    \n",
    "    assert min_test >= min_data, 'Test observations have to be equal or higher than cutoff point'\n",
    "    \n",
    "    control_urls = marketcount[marketcount[ranks] >= min_data].reset_index()\n",
    "\n",
    "    causal_control = causal_input.loc[causal_input[col].isin(control_urls[col]),]\n",
    "\n",
    "    pvt_table = causal_control.pivot_table(index=ranks, columns=col, values=metric, aggfunc=metric2).reset_index().fillna(0).set_index(ranks)\n",
    "\n",
    "    pvt_table = pvt_table.rolling(roll).mean()\n",
    "\n",
    "    pvt_table = pvt_table[roll-1:]\n",
    "\n",
    "    causal_control = pvt_table.melt(ignore_index=False).reset_index().sort_values(ranks).reset_index(drop=True)\n",
    "\n",
    "    markets = {}\n",
    "    for i in causal_control[col].unique():\n",
    "        markets[i] = causal_control[causal_control[col] == i].sort_values(ranks).reset_index(drop=True)[['value']]\n",
    "    \n",
    "    distances = {}\n",
    "    for i in causal_control[col].unique():\n",
    "        distances[i] = dtw.dtw(markets['TEST'], markets[i]).distance\n",
    "        \n",
    "    final = pd.DataFrame.from_dict(distances, orient='index', columns=['dist']).sort_values('dist', ascending=True)[1:].reset_index()\n",
    "\n",
    "    if scaling == True:\n",
    "        x = final.dist[:].values\n",
    "        min_max_scaler = preprocessing.MaxAbsScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x.reshape(-1, 1))\n",
    "        final.dist = x_scaled\n",
    "    \n",
    "    return  final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "632ba61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temp = distance(testset = pdp,\n",
    "               dataset= data,\n",
    "               metric= 'impressions' ,\n",
    "               col= 'page',\n",
    "                metric2 = 'sum',\n",
    "                min_test=320,\n",
    "                min_data=300,\n",
    "                outlier=0.90\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978378d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
